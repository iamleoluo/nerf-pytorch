#!/usr/bin/env python3
"""
å¯è¦–åŒ–éœ²ç‡Ÿè»Šæ•¸æ“šé›†çš„ç›¸æ©Ÿä½ç½®
å¹«åŠ©è¨ºæ–·ç›¸æ©Ÿå§¿æ…‹æ˜¯å¦æ­£ç¢º
"""

import json
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

def load_camera_poses(transforms_file):
    """è¼‰å…¥ç›¸æ©Ÿå§¿æ…‹æ•¸æ“š"""
    with open(transforms_file, 'r') as f:
        data = json.load(f)
    
    poses = []
    file_paths = []
    
    for frame in data['frames']:
        transform_matrix = np.array(frame['transform_matrix'])
        poses.append(transform_matrix)
        file_paths.append(frame['file_path'])
    
    return np.array(poses), file_paths, data.get('camera_angle_x', 0)

def extract_camera_positions_and_directions(poses):
    """æå–ç›¸æ©Ÿä½ç½®å’Œæœå‘"""
    positions = poses[:, :3, 3]  # ä½ç½® (x, y, z)
    
    # ç›¸æ©Ÿæœå‘ (zè»¸æ–¹å‘ï¼Œä½†è¦å–è² å€¼å› ç‚ºç›¸æ©Ÿæœå‘æ˜¯-z)
    directions = -poses[:, :3, 2]
    
    # ç›¸æ©Ÿä¸Šæ–¹å‘ (yè»¸æ–¹å‘)
    up_vectors = poses[:, :3, 1]
    
    return positions, directions, up_vectors

def plot_camera_poses(poses, file_paths, title="Camera Poses Visualization"):
    """ç¹ªè£½ç›¸æ©Ÿä½ç½®å’Œæœå‘"""
    positions, directions, up_vectors = extract_camera_positions_and_directions(poses)
    
    fig = plt.figure(figsize=(15, 10))
    
    # 3Dè¦–åœ–
    ax1 = fig.add_subplot(221, projection='3d')
    
    # ç¹ªè£½ç›¸æ©Ÿä½ç½®
    ax1.scatter(positions[:, 0], positions[:, 1], positions[:, 2], 
               c=range(len(positions)), cmap='viridis', s=50)
    
    # ç¹ªè£½ç›¸æ©Ÿæœå‘
    scale = 0.1
    ax1.quiver(positions[:, 0], positions[:, 1], positions[:, 2],
              directions[:, 0], directions[:, 1], directions[:, 2],
              length=scale, color='red', alpha=0.7)
    
    ax1.set_xlabel('X')
    ax1.set_ylabel('Y')
    ax1.set_zlabel('Z')
    ax1.set_title('3D Camera Positions and Orientations')
    
    # XYå¹³é¢è¦–åœ–
    ax2 = fig.add_subplot(222)
    ax2.scatter(positions[:, 0], positions[:, 1], c=range(len(positions)), cmap='viridis')
    ax2.quiver(positions[:, 0], positions[:, 1], 
              directions[:, 0], directions[:, 1], 
              scale=5, color='red', alpha=0.7)
    ax2.set_xlabel('X')
    ax2.set_ylabel('Y')
    ax2.set_title('XY Plane View (Top View)')
    ax2.grid(True)
    ax2.axis('equal')
    
    # XZå¹³é¢è¦–åœ–
    ax3 = fig.add_subplot(223)
    ax3.scatter(positions[:, 0], positions[:, 2], c=range(len(positions)), cmap='viridis')
    ax3.quiver(positions[:, 0], positions[:, 2], 
              directions[:, 0], directions[:, 2], 
              scale=5, color='red', alpha=0.7)
    ax3.set_xlabel('X')
    ax3.set_ylabel('Z')
    ax3.set_title('XZ Plane View (Side View)')
    ax3.grid(True)
    ax3.axis('equal')
    
    # YZå¹³é¢è¦–åœ–
    ax4 = fig.add_subplot(224)
    ax4.scatter(positions[:, 1], positions[:, 2], c=range(len(positions)), cmap='viridis')
    ax4.quiver(positions[:, 1], positions[:, 2], 
              directions[:, 1], directions[:, 2], 
              scale=5, color='red', alpha=0.7)
    ax4.set_xlabel('Y')
    ax4.set_ylabel('Z')
    ax4.set_title('YZ Plane View (Front View)')
    ax4.grid(True)
    ax4.axis('equal')
    
    plt.tight_layout()
    plt.suptitle(title, fontsize=16, y=0.98)
    plt.show()
    
    return positions, directions

def analyze_camera_distribution(positions, directions):
    """åˆ†æç›¸æ©Ÿåˆ†ä½ˆ"""
    print("ğŸ“Š ç›¸æ©Ÿä½ç½®åˆ†æ")
    print("=" * 50)
    
    print(f"ç›¸æ©Ÿæ•¸é‡: {len(positions)}")
    print(f"ä½ç½®ç¯„åœ:")
    print(f"  X: {positions[:, 0].min():.3f} ~ {positions[:, 0].max():.3f}")
    print(f"  Y: {positions[:, 1].min():.3f} ~ {positions[:, 1].max():.3f}")
    print(f"  Z: {positions[:, 2].min():.3f} ~ {positions[:, 2].max():.3f}")
    
    # è¨ˆç®—ç›¸æ©Ÿé–“è·é›¢
    center = np.mean(positions, axis=0)
    distances = np.linalg.norm(positions - center, axis=1)
    print(f"\nè·é›¢ä¸­å¿ƒé»:")
    print(f"  å¹³å‡è·é›¢: {distances.mean():.3f}")
    print(f"  æœ€å°è·é›¢: {distances.min():.3f}")
    print(f"  æœ€å¤§è·é›¢: {distances.max():.3f}")
    print(f"  æ¨™æº–å·®: {distances.std():.3f}")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰é‡è¤‡æˆ–éè¿‘çš„ç›¸æ©Ÿ
    min_distance = float('inf')
    for i in range(len(positions)):
        for j in range(i+1, len(positions)):
            dist = np.linalg.norm(positions[i] - positions[j])
            min_distance = min(min_distance, dist)
    
    print(f"\nç›¸æ©Ÿé–“æœ€å°è·é›¢: {min_distance:.6f}")
    if min_distance < 0.001:
        print("âš ï¸  è­¦å‘Š: ç™¼ç¾ç›¸æ©Ÿä½ç½®éæ–¼æ¥è¿‘æˆ–é‡è¤‡!")
    
    # æª¢æŸ¥æœå‘åˆ†ä½ˆ
    directions_norm = directions / np.linalg.norm(directions, axis=1, keepdims=True)
    dot_products = np.dot(directions_norm, directions_norm.T)
    
    # æ‰¾å‡ºæœå‘æœ€ç›¸ä¼¼çš„ç›¸æ©Ÿå°
    np.fill_diagonal(dot_products, -1)  # å¿½ç•¥è‡ªå·±
    max_similarity = np.max(dot_products)
    print(f"\nç›¸æ©Ÿæœå‘æœ€å¤§ç›¸ä¼¼åº¦: {max_similarity:.3f}")
    if max_similarity > 0.99:
        print("âš ï¸  è­¦å‘Š: ç™¼ç¾ç›¸æ©Ÿæœå‘éæ–¼ç›¸ä¼¼!")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¥ éœ²ç‡Ÿè»Šæ•¸æ“šé›†ç›¸æ©Ÿä½ç½®å¯è¦–åŒ–")
    print("=" * 50)
    
    # è¼‰å…¥ä¸åŒçš„transformsæ–‡ä»¶
    datasets = [
        ("data/nerf_synthetic/camper/transforms_train.json", "Training Set Camera Poses"),
        ("data/nerf_synthetic/camper/transforms_val.json", "Validation Set Camera Poses"),
        ("data/nerf_synthetic/camper/transforms_test.json", "Test Set Camera Poses"),
        ("data/nerf_synthetic/camper/transforms.json", "Complete Dataset Camera Poses")
    ]
    
    for transforms_file, title in datasets:
        try:
            print(f"\nğŸ“ è¼‰å…¥: {transforms_file}")
            poses, file_paths, camera_angle_x = load_camera_poses(transforms_file)
            print(f"ç›¸æ©Ÿè§’åº¦ (camera_angle_x): {camera_angle_x:.6f} å¼§åº¦ ({np.degrees(camera_angle_x):.2f}Â°)")
            
            positions, directions = plot_camera_poses(poses, file_paths, title)
            analyze_camera_distribution(positions, directions)
            
            # ä¿å­˜åœ–ç‰‡
            plt.savefig(f'camera_poses_{transforms_file.split("/")[-1].replace(".json", "")}.png', 
                       dpi=300, bbox_inches='tight')
            print(f"âœ… åœ–ç‰‡å·²ä¿å­˜: camera_poses_{transforms_file.split('/')[-1].replace('.json', '')}.png")
            
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {transforms_file}")
        except Exception as e:
            print(f"âŒ è™•ç†éŒ¯èª¤: {e}")

if __name__ == "__main__":
    main() 