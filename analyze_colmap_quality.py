#!/usr/bin/env python3
"""
åˆ†æCOLMAPé‡å»ºå“è³ªä¸¦æä¾›æ”¹é€²å»ºè­°
"""

import json
import numpy as np
import os

def analyze_camera_poses(transforms_file):
    """åˆ†æç›¸æ©Ÿå§¿æ…‹å“è³ª"""
    with open(transforms_file, 'r') as f:
        data = json.load(f)
    
    poses = []
    for frame in data['frames']:
        transform_matrix = np.array(frame['transform_matrix'])
        poses.append(transform_matrix)
    
    poses = np.array(poses)
    positions = poses[:, :3, 3]
    directions = -poses[:, :3, 2]  # ç›¸æ©Ÿæœå‘
    
    return positions, directions, data

def calculate_pose_quality_metrics(positions, directions):
    """è¨ˆç®—å§¿æ…‹å“è³ªæŒ‡æ¨™"""
    metrics = {}
    
    # 1. ä½ç½®åˆ†ä½ˆåˆ†æ
    center = np.mean(positions, axis=0)
    distances_from_center = np.linalg.norm(positions - center, axis=1)
    
    metrics['position_spread'] = {
        'mean_distance': distances_from_center.mean(),
        'std_distance': distances_from_center.std(),
        'min_distance': distances_from_center.min(),
        'max_distance': distances_from_center.max()
    }
    
    # 2. ç›¸æ©Ÿé–“è·é›¢åˆ†æ
    min_distance = float('inf')
    distances = []
    for i in range(len(positions)):
        for j in range(i+1, len(positions)):
            dist = np.linalg.norm(positions[i] - positions[j])
            distances.append(dist)
            min_distance = min(min_distance, dist)
    
    metrics['inter_camera_distances'] = {
        'min_distance': min_distance,
        'mean_distance': np.mean(distances),
        'std_distance': np.std(distances)
    }
    
    # 3. è¦–è§’å¤šæ¨£æ€§åˆ†æ
    directions_norm = directions / np.linalg.norm(directions, axis=1, keepdims=True)
    dot_products = np.dot(directions_norm, directions_norm.T)
    
    # ç§»é™¤å°è§’ç·šå…ƒç´ 
    mask = ~np.eye(dot_products.shape[0], dtype=bool)
    similarities = dot_products[mask]
    
    metrics['viewing_diversity'] = {
        'max_similarity': similarities.max(),
        'mean_similarity': similarities.mean(),
        'min_similarity': similarities.min(),
        'std_similarity': similarities.std()
    }
    
    # 4. åŸºç·šé•·åº¦åˆ†æ (é‡è¦ç”¨æ–¼ç«‹é«”è¦–è¦º)
    baseline_lengths = []
    for i in range(len(positions)):
        for j in range(i+1, len(positions)):
            baseline = np.linalg.norm(positions[i] - positions[j])
            baseline_lengths.append(baseline)
    
    metrics['baseline_analysis'] = {
        'mean_baseline': np.mean(baseline_lengths),
        'std_baseline': np.std(baseline_lengths),
        'min_baseline': np.min(baseline_lengths),
        'max_baseline': np.max(baseline_lengths)
    }
    
    return metrics

def diagnose_problems(metrics):
    """è¨ºæ–·å•é¡Œä¸¦æä¾›å»ºè­°"""
    problems = []
    suggestions = []
    
    # æª¢æŸ¥è¦–è§’å¤šæ¨£æ€§
    if metrics['viewing_diversity']['max_similarity'] > 0.99:
        problems.append("âŒ ç›¸æ©Ÿæœå‘éæ–¼ç›¸ä¼¼ (max similarity > 0.99)")
        suggestions.append("ğŸ“ å»ºè­°: å¢åŠ æ›´å¤šä¸åŒè§’åº¦çš„ç…§ç‰‡ï¼Œç‰¹åˆ¥æ˜¯å¾ä¸åŒé«˜åº¦å’Œæ–¹ä½æ‹æ”")
    
    if metrics['viewing_diversity']['mean_similarity'] > 0.8:
        problems.append("âŒ æ•´é«”è¦–è§’å¤šæ¨£æ€§ä¸è¶³ (mean similarity > 0.8)")
        suggestions.append("ğŸ“ å»ºè­°: æ‹æ”æ™‚æ‡‰è©²åœç¹ç‰©é«”360åº¦ç§»å‹•ï¼Œä¸¦æ”¹è®Šé«˜åº¦")
    
    # æª¢æŸ¥ç›¸æ©Ÿé–“è·é›¢
    if metrics['inter_camera_distances']['min_distance'] < 0.05:
        problems.append("âŒ ç›¸æ©Ÿä½ç½®éæ–¼æ¥è¿‘ (min distance < 0.05)")
        suggestions.append("ğŸ“ å»ºè­°: å¢åŠ ç›¸æ©Ÿé–“çš„è·é›¢ï¼Œé¿å…é€£çºŒç…§ç‰‡éæ–¼ç›¸ä¼¼")
    
    # æª¢æŸ¥åŸºç·šé•·åº¦
    if metrics['baseline_analysis']['mean_baseline'] < 0.1:
        problems.append("âŒ åŸºç·šé•·åº¦éçŸ­ï¼Œå½±éŸ¿æ·±åº¦ä¼°è¨ˆ")
        suggestions.append("ğŸ“ å»ºè­°: å¢åŠ ç›¸æ©Ÿç§»å‹•è·é›¢ï¼Œæä¾›æ›´å¥½çš„ç«‹é«”è¦–è¦ºç·šç´¢")
    
    # æª¢æŸ¥ä½ç½®åˆ†ä½ˆ
    if metrics['position_spread']['std_distance'] < 0.1:
        problems.append("âŒ ç›¸æ©Ÿä½ç½®åˆ†ä½ˆéæ–¼é›†ä¸­")
        suggestions.append("ğŸ“ å»ºè­°: å¾æ›´å¤šä¸åŒè·é›¢æ‹æ”ç‰©é«”")
    
    return problems, suggestions

def suggest_improvements():
    """æä¾›å…·é«”çš„æ”¹é€²å»ºè­°"""
    print("\nğŸ¯ COLMAPé‡å»ºå“è³ªæ”¹é€²å»ºè­°")
    print("=" * 60)
    
    print("\nğŸ“¸ æ‹æ”æŠ€å·§æ”¹é€²:")
    print("1. åœç¹éœ²ç‡Ÿè»Š360åº¦æ‹æ”ï¼Œæ¯15-30åº¦æ‹ä¸€å¼µ")
    print("2. å¾ä¸åŒé«˜åº¦æ‹æ” (è¹²ä¸‹ã€æ­£å¸¸é«˜åº¦ã€èˆ‰é«˜)")
    print("3. æ”¹è®Šèˆ‡éœ²ç‡Ÿè»Šçš„è·é›¢ (è¿‘æ™¯ã€ä¸­æ™¯ã€é æ™¯)")
    print("4. ç¢ºä¿ç›¸é„°ç…§ç‰‡æœ‰60-80%çš„é‡ç–Š")
    print("5. é¿å…ç´”å¹³ç§»ï¼Œå¢åŠ ä¸€äº›æ—‹è½‰è§’åº¦")
    
    print("\nğŸ”§ COLMAPåƒæ•¸èª¿æ•´:")
    print("1. å¢åŠ ç‰¹å¾µé»æ•¸é‡: --SiftExtraction.max_num_features 8192")
    print("2. èª¿æ•´åŒ¹é…åƒæ•¸: --SiftMatching.max_ratio 0.8")
    print("3. ä½¿ç”¨æ›´åš´æ ¼çš„Bundle Adjustment")
    print("4. è€ƒæ…®ä½¿ç”¨maskä¾†æ’é™¤å¤©ç©ºç­‰ç„¡ç´‹ç†å€åŸŸ")
    
    print("\nâš™ï¸ NeRFè¨“ç·´åƒæ•¸èª¿æ•´:")
    print("1. é™ä½factorå€¼ (å¾8æ”¹ç‚º2æˆ–4)")
    print("2. å¢åŠ è¨“ç·´æ­¥æ•¸")
    print("3. èª¿æ•´å­¸ç¿’ç‡ç­–ç•¥")
    print("4. è€ƒæ…®ä½¿ç”¨æ›´å¤šçš„æ¡æ¨£é»")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ” COLMAPé‡å»ºå“è³ªåˆ†æ")
    print("=" * 50)
    
    transforms_file = "data/nerf_synthetic/camper/transforms.json"
    
    if not os.path.exists(transforms_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {transforms_file}")
        return
    
    # è¼‰å…¥å’Œåˆ†ææ•¸æ“š
    positions, directions, data = analyze_camera_poses(transforms_file)
    metrics = calculate_pose_quality_metrics(positions, directions)
    
    # é¡¯ç¤ºåŸºæœ¬ä¿¡æ¯
    print(f"\nğŸ“Š åŸºæœ¬ä¿¡æ¯:")
    print(f"ç›¸æ©Ÿæ•¸é‡: {len(positions)}")
    print(f"ç›¸æ©Ÿè§’åº¦: {data.get('camera_angle_x', 0):.6f} å¼§åº¦ ({np.degrees(data.get('camera_angle_x', 0)):.2f}Â°)")
    
    # é¡¯ç¤ºè©³ç´°æŒ‡æ¨™
    print(f"\nğŸ“ ä½ç½®åˆ†ä½ˆæŒ‡æ¨™:")
    pos_metrics = metrics['position_spread']
    print(f"  å¹³å‡è·é›¢ä¸­å¿ƒ: {pos_metrics['mean_distance']:.3f}")
    print(f"  è·é›¢æ¨™æº–å·®: {pos_metrics['std_distance']:.3f}")
    print(f"  è·é›¢ç¯„åœ: {pos_metrics['min_distance']:.3f} ~ {pos_metrics['max_distance']:.3f}")
    
    print(f"\nğŸ“ ç›¸æ©Ÿé–“è·é›¢:")
    dist_metrics = metrics['inter_camera_distances']
    print(f"  æœ€å°è·é›¢: {dist_metrics['min_distance']:.6f}")
    print(f"  å¹³å‡è·é›¢: {dist_metrics['mean_distance']:.3f}")
    print(f"  è·é›¢æ¨™æº–å·®: {dist_metrics['std_distance']:.3f}")
    
    print(f"\nğŸ‘ï¸ è¦–è§’å¤šæ¨£æ€§:")
    view_metrics = metrics['viewing_diversity']
    print(f"  æœ€å¤§ç›¸ä¼¼åº¦: {view_metrics['max_similarity']:.6f}")
    print(f"  å¹³å‡ç›¸ä¼¼åº¦: {view_metrics['mean_similarity']:.3f}")
    print(f"  æœ€å°ç›¸ä¼¼åº¦: {view_metrics['min_similarity']:.3f}")
    
    print(f"\nğŸ“ åŸºç·šåˆ†æ:")
    baseline_metrics = metrics['baseline_analysis']
    print(f"  å¹³å‡åŸºç·š: {baseline_metrics['mean_baseline']:.3f}")
    print(f"  åŸºç·šæ¨™æº–å·®: {baseline_metrics['std_baseline']:.3f}")
    print(f"  åŸºç·šç¯„åœ: {baseline_metrics['min_baseline']:.3f} ~ {baseline_metrics['max_baseline']:.3f}")
    
    # è¨ºæ–·å•é¡Œ
    problems, suggestions = diagnose_problems(metrics)
    
    if problems:
        print(f"\nğŸš¨ ç™¼ç¾çš„å•é¡Œ:")
        for problem in problems:
            print(f"  {problem}")
        
        print(f"\nğŸ’¡ æ”¹é€²å»ºè­°:")
        for suggestion in suggestions:
            print(f"  {suggestion}")
    else:
        print(f"\nâœ… ç›¸æ©Ÿå§¿æ…‹å“è³ªè‰¯å¥½!")
    
    # æä¾›å…·é«”æ”¹é€²å»ºè­°
    suggest_improvements()

if __name__ == "__main__":
    main() 