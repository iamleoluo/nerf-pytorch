#!/usr/bin/env python3
"""
ç›¸æ©Ÿä½ç½®å’Œæœå‘è¦–è¦ºåŒ–å·¥å…·
åˆ†æNeRFæ•¸æ“šé›†ä¸­çš„ç›¸æ©Ÿåˆ†ä½ˆ
å·¥å…·ç‰ˆæœ¬ - æ”¾ç½®åœ¨tools/analysisç›®éŒ„
"""

import numpy as np
import json
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import os
import sys

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

def load_transforms(dataset_path):
    """è¼‰å…¥transforms.jsonæ–‡ä»¶"""
    if not os.path.exists(dataset_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ•¸æ“šé›†æ–‡ä»¶: {dataset_path}")
        return None
    
    with open(dataset_path, 'r') as f:
        data = json.load(f)
    
    print(f"âœ… è¼‰å…¥æ•¸æ“šé›†ï¼ŒåŒ…å« {len(data['frames'])} å€‹ç›¸æ©Ÿ")
    return data

def extract_camera_poses(transforms_data):
    """æå–ç›¸æ©Ÿä½ç½®å’Œæœå‘"""
    positions = []
    directions = []
    up_vectors = []
    
    for frame in transforms_data['frames']:
        transform = np.array(frame['transform_matrix'])
        
        # æå–ä½ç½®
        position = transform[:3, 3]
        positions.append(position)
        
        # æå–æœå‘ (NeRFä¸­ç›¸æ©Ÿæœå‘-Zæ–¹å‘)
        direction = -transform[:3, 2]
        directions.append(direction)
        
        # æå–ä¸Šæ–¹å‘ (Yè»¸)
        up = transform[:3, 1]
        up_vectors.append(up)
    
    return np.array(positions), np.array(directions), np.array(up_vectors)

def analyze_camera_distribution(positions, directions):
    """åˆ†æç›¸æ©Ÿåˆ†ä½ˆ"""
    print("\nğŸ“Š ç›¸æ©Ÿåˆ†ä½ˆåˆ†æ")
    print("=" * 50)
    
    # ä½ç½®çµ±è¨ˆ
    center = np.mean(positions, axis=0)
    distances = np.linalg.norm(positions - center, axis=1)
    
    print(f"ç›¸æ©Ÿä½ç½®çµ±è¨ˆ:")
    print(f"  ä¸­å¿ƒé»: [{center[0]:6.3f}, {center[1]:6.3f}, {center[2]:6.3f}]")
    print(f"  å¹³å‡è·é›¢ä¸­å¿ƒ: {distances.mean():.3f}")
    print(f"  è·é›¢æ¨™æº–å·®: {distances.std():.3f}")
    print(f"  æœ€å°è·é›¢: {distances.min():.3f}")
    print(f"  æœ€å¤§è·é›¢: {distances.max():.3f}")
    
    # æœå‘çµ±è¨ˆ
    directions_norm = directions / np.linalg.norm(directions, axis=1, keepdims=True)
    
    # è¨ˆç®—ç›¸æ©Ÿæœå‘çš„ç›¸ä¼¼åº¦
    dot_products = np.dot(directions_norm, directions_norm.T)
    np.fill_diagonal(dot_products, -1)  # æ’é™¤è‡ªå·±èˆ‡è‡ªå·±çš„æ¯”è¼ƒ
    max_similarity = np.max(dot_products)
    min_similarity = np.min(dot_products)
    avg_similarity = np.mean(dot_products[dot_products > -1])
    
    print(f"\nç›¸æ©Ÿæœå‘çµ±è¨ˆ:")
    print(f"  æœ€å¤§ç›¸ä¼¼åº¦: {max_similarity:.3f}")
    print(f"  æœ€å°ç›¸ä¼¼åº¦: {min_similarity:.3f}")
    print(f"  å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.3f}")
    
    # æª¢æŸ¥ç›¸æ©Ÿæ˜¯å¦æœå‘ä¸­å¿ƒ
    to_center = center - positions
    to_center_norm = to_center / np.linalg.norm(to_center, axis=1, keepdims=True)
    center_alignment = np.sum(directions_norm * to_center_norm, axis=1)
    
    print(f"\nç›¸æ©Ÿæœå‘ä¸­å¿ƒåˆ†æ:")
    print(f"  å¹³å‡æœå‘ä¸­å¿ƒåº¦: {center_alignment.mean():.3f}")
    print(f"  æœå‘ä¸­å¿ƒåº¦æ¨™æº–å·®: {center_alignment.std():.3f}")
    print(f"  æœå‘ä¸­å¿ƒçš„ç›¸æ©Ÿæ•¸: {np.sum(center_alignment > 0.5)}/{len(center_alignment)}")
    
    return {
        'center': center,
        'distances': distances,
        'max_similarity': max_similarity,
        'center_alignment': center_alignment.mean()
    }

def visualize_cameras_3d(positions, directions, save_path=None):
    """3Dè¦–è¦ºåŒ–ç›¸æ©Ÿä½ç½®å’Œæœå‘"""
    fig = plt.figure(figsize=(12, 10))
    ax = fig.add_subplot(111, projection='3d')
    
    # ç¹ªè£½ç›¸æ©Ÿä½ç½®
    ax.scatter(positions[:, 0], positions[:, 1], positions[:, 2], 
              c='red', s=50, alpha=0.7, label='ç›¸æ©Ÿä½ç½®')
    
    # ç¹ªè£½ç›¸æ©Ÿæœå‘
    scale = 0.1  # ç®­é ­é•·åº¦ç¸®æ”¾
    ax.quiver(positions[:, 0], positions[:, 1], positions[:, 2],
              directions[:, 0] * scale, directions[:, 1] * scale, directions[:, 2] * scale,
              color='blue', alpha=0.6, label='ç›¸æ©Ÿæœå‘')
    
    # è¨ˆç®—ä¸¦ç¹ªè£½å ´æ™¯ä¸­å¿ƒ
    center = np.mean(positions, axis=0)
    ax.scatter(center[0], center[1], center[2], 
              c='green', s=100, marker='*', label='å ´æ™¯ä¸­å¿ƒ')
    
    # è¨­ç½®è»¸æ¨™ç±¤å’Œæ¨™é¡Œ
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('Z')
    ax.set_title('ç›¸æ©Ÿä½ç½®å’Œæœå‘åˆ†ä½ˆ (NeRFåº§æ¨™ç³»)')
    ax.legend()
    
    # è¨­ç½®ç›¸ç­‰çš„è»¸æ¯”ä¾‹
    max_range = np.array([positions[:, 0].max() - positions[:, 0].min(),
                         positions[:, 1].max() - positions[:, 1].min(),
                         positions[:, 2].max() - positions[:, 2].min()]).max() / 2.0
    mid_x = (positions[:, 0].max() + positions[:, 0].min()) * 0.5
    mid_y = (positions[:, 1].max() + positions[:, 1].min()) * 0.5
    mid_z = (positions[:, 2].max() + positions[:, 2].min()) * 0.5
    
    ax.set_xlim(mid_x - max_range, mid_x + max_range)
    ax.set_ylim(mid_y - max_range, mid_y + max_range)
    ax.set_zlim(mid_z - max_range, mid_z + max_range)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ 3Dè¦–è¦ºåŒ–ä¿å­˜åˆ°: {save_path}")
    
    plt.show()

def visualize_camera_distribution(positions, directions, save_path=None):
    """2DæŠ•å½±è¦–è¦ºåŒ–ç›¸æ©Ÿåˆ†ä½ˆ"""
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # XYå¹³é¢æŠ•å½±
    axes[0, 0].scatter(positions[:, 0], positions[:, 1], c='red', alpha=0.7)
    axes[0, 0].quiver(positions[:, 0], positions[:, 1], 
                     directions[:, 0], directions[:, 1], 
                     scale=5, alpha=0.6, color='blue')
    axes[0, 0].set_xlabel('X')
    axes[0, 0].set_ylabel('Y')
    axes[0, 0].set_title('XYå¹³é¢æŠ•å½±')
    axes[0, 0].grid(True, alpha=0.3)
    axes[0, 0].axis('equal')
    
    # XZå¹³é¢æŠ•å½±
    axes[0, 1].scatter(positions[:, 0], positions[:, 2], c='red', alpha=0.7)
    axes[0, 1].quiver(positions[:, 0], positions[:, 2], 
                     directions[:, 0], directions[:, 2], 
                     scale=5, alpha=0.6, color='blue')
    axes[0, 1].set_xlabel('X')
    axes[0, 1].set_ylabel('Z')
    axes[0, 1].set_title('XZå¹³é¢æŠ•å½±')
    axes[0, 1].grid(True, alpha=0.3)
    axes[0, 1].axis('equal')
    
    # YZå¹³é¢æŠ•å½±
    axes[1, 0].scatter(positions[:, 1], positions[:, 2], c='red', alpha=0.7)
    axes[1, 0].quiver(positions[:, 1], positions[:, 2], 
                     directions[:, 1], directions[:, 2], 
                     scale=5, alpha=0.6, color='blue')
    axes[1, 0].set_xlabel('Y')
    axes[1, 0].set_ylabel('Z')
    axes[1, 0].set_title('YZå¹³é¢æŠ•å½±')
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].axis('equal')
    
    # è·é›¢åˆ†ä½ˆç›´æ–¹åœ–
    center = np.mean(positions, axis=0)
    distances = np.linalg.norm(positions - center, axis=1)
    axes[1, 1].hist(distances, bins=20, alpha=0.7, color='green')
    axes[1, 1].set_xlabel('è·é›¢ä¸­å¿ƒ')
    axes[1, 1].set_ylabel('ç›¸æ©Ÿæ•¸é‡')
    axes[1, 1].set_title('ç›¸æ©Ÿè·é›¢ä¸­å¿ƒåˆ†ä½ˆ')
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ 2Dåˆ†ä½ˆåœ–ä¿å­˜åˆ°: {save_path}")
    
    plt.show()

def generate_quality_report(stats, dataset_name="Unknown"):
    """ç”Ÿæˆå“è³ªå ±å‘Š"""
    print(f"\nğŸ“‹ æ•¸æ“šé›†å“è³ªå ±å‘Š: {dataset_name}")
    print("=" * 60)
    
    # è©•ä¼°æ¨™æº–
    print("è©•ä¼°æ¨™æº–:")
    print("  ç›¸æ©Ÿæœå‘å¤šæ¨£æ€§: æœ€å¤§ç›¸ä¼¼åº¦ < 0.95 ç‚ºè‰¯å¥½")
    print("  ç›¸æ©Ÿæœå‘ä¸­å¿ƒ: å¹³å‡æœå‘ä¸­å¿ƒåº¦ > 0.3 ç‚ºè‰¯å¥½")
    print("  ä½ç½®åˆ†ä½ˆ: è·é›¢æ¨™æº–å·® > 0.1 ç‚ºè‰¯å¥½")
    
    print("\nè©•ä¼°çµæœ:")
    
    # æœå‘å¤šæ¨£æ€§
    if stats['max_similarity'] < 0.95:
        print("  âœ… ç›¸æ©Ÿæœå‘å¤šæ¨£æ€§: è‰¯å¥½")
    else:
        print("  âš ï¸ ç›¸æ©Ÿæœå‘å¤šæ¨£æ€§: éœ€è¦æ”¹å–„")
    
    # æœå‘ä¸­å¿ƒ
    if stats['center_alignment'] > 0.3:
        print("  âœ… ç›¸æ©Ÿæœå‘ä¸­å¿ƒ: è‰¯å¥½")
    else:
        print("  âš ï¸ ç›¸æ©Ÿæœå‘ä¸­å¿ƒ: éœ€è¦æ”¹å–„")
    
    # ä½ç½®åˆ†ä½ˆ
    if stats['distances'].std() > 0.1:
        print("  âœ… ä½ç½®åˆ†ä½ˆ: è‰¯å¥½")
    else:
        print("  âš ï¸ ä½ç½®åˆ†ä½ˆ: éœ€è¦æ”¹å–„")
    
    # ç¸½é«”è©•ä¼°
    good_count = sum([
        stats['max_similarity'] < 0.95,
        stats['center_alignment'] > 0.3,
        stats['distances'].std() > 0.1
    ])
    
    if good_count == 3:
        print("\nğŸ‰ ç¸½é«”è©•ä¼°: å„ªç§€")
    elif good_count == 2:
        print("\nğŸ‘ ç¸½é«”è©•ä¼°: è‰¯å¥½")
    elif good_count == 1:
        print("\nâš ï¸ ç¸½é«”è©•ä¼°: éœ€è¦æ”¹å–„")
    else:
        print("\nâŒ ç¸½é«”è©•ä¼°: å“è³ªè¼ƒå·®")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ“· ç›¸æ©Ÿä½ç½®å’Œæœå‘è¦–è¦ºåŒ–å·¥å…·")
    print("=" * 50)
    
    # é»˜èªæ•¸æ“šé›†è·¯å¾‘
    dataset_path = "../../data/nerf_synthetic/camper_fixed/transforms.json"
    
    # è¼‰å…¥æ•¸æ“š
    transforms_data = load_transforms(dataset_path)
    if transforms_data is None:
        return
    
    # æå–ç›¸æ©Ÿå§¿æ…‹
    positions, directions, up_vectors = extract_camera_poses(transforms_data)
    
    # åˆ†æåˆ†ä½ˆ
    stats = analyze_camera_distribution(positions, directions)
    
    # ç”Ÿæˆå“è³ªå ±å‘Š
    generate_quality_report(stats, "camper_fixed")
    
    # è¦–è¦ºåŒ–
    print("\nğŸ¨ ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨...")
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir = "../../outputs/camera_analysis"
    os.makedirs(output_dir, exist_ok=True)
    
    # 3Dè¦–è¦ºåŒ–
    visualize_cameras_3d(positions, directions, 
                        os.path.join(output_dir, "cameras_3d.png"))
    
    # 2Dåˆ†ä½ˆåœ–
    visualize_camera_distribution(positions, directions,
                                 os.path.join(output_dir, "cameras_2d.png"))
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼åœ–è¡¨ä¿å­˜åœ¨: {output_dir}")

if __name__ == "__main__":
    main() 